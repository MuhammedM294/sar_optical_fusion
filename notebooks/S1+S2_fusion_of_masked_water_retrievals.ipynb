{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rationale for the fusion of independent Sentinel-1 and Sentinel-2 exclusion masks and inland water retrievals\n",
    "\n",
    "Multi-sensor fusion pipeline that combines independent exclusion masks and indipendent water retrievals derived from Sentinel-1 (S1) SAR and Sentinel-2 (S2) optical data. Exclusion masks are merged using a decision-level rule. The final water extent is estimated through a Gaussian fusion model that exploits the mean and standard deviation of the sensor-specific retrievals, which have been previously filtered using the exclusion masks.\n",
    "For further details please refer to the journal submission.\n",
    "\n",
    "## Workflow Overview\n",
    "1. Load S1 and S2 predictions (in the form of mean and standard deviation) previously computed.\n",
    "2. Upload/generate indipendent exclusion masks for the S1 and S2 acquisitions from which the predictions are derived.\n",
    "3. Fusion of indipendent masked Gaussian distributions (i.e., masked S1 and S2 predictions) from both sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import pystac_client\n",
    "import odc.stac\n",
    "from odc.geo.geobox import GeoBox\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for S1 predictions\n",
    "s1mu_result_path = \"path/to/your/s1mufile.tif\"\n",
    "s1sigma_result_path = \"path/to/your/s1sigmafile.tif\"\n",
    "\n",
    "# File paths for S2 predictions\n",
    "s2mu_result_path = \"path/to/your/s2mufile.tif\"\n",
    "s2sigma_result_path = \"path/to/your/s2sigmafile.tif\"\n",
    "\n",
    "# Spatial resolution and CRS\n",
    "dx = 0.0001  # 10m resolution\n",
    "epsg = 4326\n",
    "time_format = \"%Y-%m-%d\"\n",
    "\n",
    "# Temporal queries for S1\n",
    "start_date_s1 = datetime(year=2023, month=6, day=20) # Set the date to the S1 acquisition date (same scene as the prediction)\n",
    "end_date_s1 = start_date_s1 + timedelta(days=1)\n",
    "date_query_s1 = start_date_s1.strftime(time_format) + \"/\" + end_date_s1.strftime(time_format)\n",
    "\n",
    "# Temporal queries for S2\n",
    "start_date_s2 = datetime(year=2023, month=6, day=20) # Set the date to the S2 acquisition date (same scene as the prediction)\n",
    "end_date_s2 = start_date_s2 + timedelta(days=1)\n",
    "date_query_s2 = start_date_s2.strftime(time_format) + \"/\" + end_date_s2.strftime(time_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_pixel_S1(data):\n",
    "    \"\"\"\n",
    "    Return valid S1 observations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : xarray.DataArray\n",
    "        GFM exclusion mask\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xarray.DataArray : Boolean mask where True indicates valid pixels\n",
    "    \"\"\"\n",
    "    return data == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndvi_band(data):\n",
    "    \"\"\"\n",
    "    Compute NDVI from Sentinel-2 NIR and Red bands.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : xarray.Dataset\n",
    "        Dataset containing 'nir' and 'red' bands\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xarray.DataArray : NDVI values\n",
    "    \"\"\"\n",
    "    return (data.nir - data.red) / (data.nir + data.red + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_pixel_s2(data):\n",
    "    \"\"\"\n",
    "    Return valid S2 observations based on Scene Classification Layer (SCL).\n",
    "    \n",
    "    Excludes: topographic shadow, cloud shadow, cloud medium/high probability, thin cirrus\n",
    "    Valid classes: 4-7 (vegetation, not vegetated, water, unclassified) and 11 (snow/ice)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : xarray.DataArray\n",
    "        SCL classification data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xarray.DataArray : Boolean mask where True indicates valid pixels\n",
    "    \"\"\"\n",
    "    return ((data > 3) & (data < 8)) | (data == 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_masked_binary_masks(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Fuse two binary masks with NaN handling.\n",
    "    \n",
    "    Logic:\n",
    "    - If both mask1 and mask2 are NaN → result is NaN\n",
    "    - If either mask is 1 → result is 1\n",
    "    - If one is 0 and the other is NaN → result is 0\n",
    "    - If both are 0 → result is 0\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mask1, mask2 : xarray.DataArray\n",
    "        Binary masks (0, 1, or NaN)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    xarray.DataArray : Fused mask\n",
    "    \"\"\"\n",
    "    result = xr.where((mask1 == 1) | (mask2 == 1), 1, 0)\n",
    "    fused_masked = result.where(~(xr.ufuncs.isnan(mask1) & xr.ufuncs.isnan(mask2)))\n",
    "    return fused_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_gaussians(mu1, sigma1, mu2, sigma2):\n",
    "    \"\"\"\n",
    "    Fuse two Gaussian distributions using optimal weighting.\n",
    "    \n",
    "    The fusion formula:\n",
    "    - fused_mu = (var2 * mu1 + var1 * mu2) / (var1 + var2)\n",
    "    - fused_var = (var1 * var2) / (var1 + var2)\n",
    "    \n",
    "    Handles cases where only one sensor is valid:\n",
    "    - If both valid → use fusion formula\n",
    "    - If only one valid → use that sensor's mu and sigma\n",
    "    - If neither valid → output NaN\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mu1, sigma1 : xarray.DataArray\n",
    "        Mean and std dev for first Gaussian (S1)\n",
    "    mu2, sigma2 : xarray.DataArray\n",
    "        Mean and std dev for second Gaussian (S2)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fused_mu, fused_sigma : xarray.DataArray\n",
    "        Fused mean and standard deviation\n",
    "    \"\"\"\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    # Replace zero or negative sigma values with small epsilon\n",
    "    sigma1 = xr.where((~xr.ufuncs.isfinite(sigma1)) | (sigma1 <= 0), epsilon, sigma1)\n",
    "    sigma2 = xr.where((~xr.ufuncs.isfinite(sigma2)) | (sigma2 <= 0), epsilon, sigma2)\n",
    "\n",
    "    # Compute variances\n",
    "    var1 = sigma1 ** 2\n",
    "    var2 = sigma2 ** 2\n",
    "\n",
    "    # Validity masks\n",
    "    valid_1 = xr.ufuncs.isfinite(mu1) & xr.ufuncs.isfinite(sigma1)\n",
    "    valid_2 = xr.ufuncs.isfinite(mu2) & xr.ufuncs.isfinite(sigma2)\n",
    "    both_valid = valid_1 & valid_2\n",
    "    only_1_valid = valid_1 & ~valid_2\n",
    "    only_2_valid = valid_2 & ~valid_1\n",
    "\n",
    "    # Initialize output\n",
    "    fused_mu = xr.full_like(mu1, np.nan)\n",
    "    fused_sigma = xr.full_like(sigma1, np.nan)\n",
    "\n",
    "    # Fusion formula where both valid\n",
    "    fused_mu_both = (var2 * mu1 + var1 * mu2) / (var1 + var2)\n",
    "    fused_var_both = (var1 * var2) / (var1 + var2)\n",
    "    fused_sigma_both = np.sqrt(fused_var_both)\n",
    "\n",
    "    # Apply conditions\n",
    "    fused_mu = xr.where(both_valid, fused_mu_both, fused_mu)\n",
    "    fused_sigma = xr.where(both_valid, fused_sigma_both, fused_sigma)\n",
    "\n",
    "    fused_mu = xr.where(only_1_valid, mu1, fused_mu)\n",
    "    fused_sigma = xr.where(only_1_valid, sigma1, fused_sigma)\n",
    "\n",
    "    fused_mu = xr.where(only_2_valid, mu2, fused_mu)\n",
    "    fused_sigma = xr.where(only_2_valid, sigma2, fused_sigma)\n",
    "\n",
    "    return fused_mu, fused_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentinel-1 data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load S1 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load S1 predictions\n",
    "s1_mu = rioxarray.open_rasterio(s1mu_result_path)\n",
    "s1_sigma = rioxarray.open_rasterio(s1sigma_result_path)\n",
    "\n",
    "# Reproject to WGS84, then optimize data size\n",
    "s1mu_result_latlon = s1_mu.rio.reproject(\"EPSG:4326\").round(3).astype(\"float32\")\n",
    "s1sigma_result_latlon = s1_sigma.rio.reproject(\"EPSG:4326\").round(3).astype(\"float32\")\n",
    "\n",
    "print(f\"S1 μ shape: {s1mu_result_latlon.shape}\")\n",
    "print(f\"S1 μ CRS: {s1mu_result_latlon.rio.crs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Load S1 Exclusion Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spatial bounds from S1 data\n",
    "bounds = s1mu_result_latlon.rio.bounds()\n",
    "\n",
    "# Connect to EODC STAC catalog\n",
    "client = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n",
    "\n",
    "# Search for GFM exclusion mask\n",
    "items = client.search(\n",
    "    collections=[\"GFM\"],\n",
    "    bbox=bounds,\n",
    "    datetime=date_query_s1,\n",
    "    limit=100,\n",
    ").item_collection()\n",
    "\n",
    "print(f\"{len(items)} GFM scenes found\")\n",
    "print(f\"Available assets: {items[0].assets.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geobox for datacube\n",
    "geobox = GeoBox.from_bbox(bounds, crs=f\"epsg:{epsg}\", resolution=dx)\n",
    "\n",
    "# Load GFM data into datacube\n",
    "dc = odc.stac.load(\n",
    "    items,\n",
    "    bands=[\"exclusion_mask\"],\n",
    "    chunks={'x': 512, 'y': 512},\n",
    "    geobox=geobox,\n",
    "    resampling=\"nearest\",\n",
    "    groupby=\"solar_day\"\n",
    ")\n",
    "\n",
    "# Clean up mask (remove 255 values)\n",
    "dc['exclusion_mask'] = dc.exclusion_mask.where(dc.exclusion_mask != 255)\n",
    "dc = dc.squeeze()\n",
    "\n",
    "print(f\"Datacube shape: {dc.exclusion_mask.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Apply S1 Mask and register data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validity mask for S1\n",
    "dc[\"valid_S1\"] = is_valid_pixel_S1(dc.exclusion_mask)\n",
    "\n",
    "# Coregister S1 predictions to datacube\n",
    "dc[\"S1_mu\"] = (s1mu_result_latlon\n",
    "               .rio.reproject_match(dc[\"valid_S1\"])\n",
    "               .squeeze(drop=True)\n",
    "               .rename({\"y\": \"latitude\", \"x\": \"longitude\"}))\n",
    "\n",
    "dc[\"S1_sigma\"] = (s1sigma_result_latlon\n",
    "                  .rio.reproject_match(dc[\"valid_S1\"])\n",
    "                  .squeeze(drop=True)\n",
    "                  .rename({\"y\": \"latitude\", \"x\": \"longitude\"}))\n",
    "\n",
    "print(\"S1 data successfully registered to datacube\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sentinel-2 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load S2 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load S2 predictions\n",
    "s2_mu = rioxarray.open_rasterio(s2mu_result_path)\n",
    "s2_sigma = rioxarray.open_rasterio(s2sigma_result_path)\n",
    "\n",
    "# Reproject to WGS84, then optimize data size\n",
    "s2mu_result_latlon = s2_mu.rio.reproject(\"EPSG:4326\").round(3).astype(\"float32\")\n",
    "s2sigma_result_latlon = s2_sigma.rio.reproject(\"EPSG:4326\").round(3).astype(\"float32\")\n",
    "\n",
    "print(f\"S2 μ shape: {s2mu_result_latlon.shape}\")\n",
    "print(f\"S2 μ CRS: {s2mu_result_latlon.rio.crs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Load S2 Scene Classification and Spectral Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spatial bounds\n",
    "bounds = s2mu_result_latlon.rio.bounds()\n",
    "\n",
    "# Search for Sentinel-2 data\n",
    "items_s2 = pystac_client.Client.open(\n",
    "    \"https://earth-search.aws.element84.com/v1\"\n",
    ").search(\n",
    "    bbox=bounds,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    datetime=date_query_s2,\n",
    "    limit=100,\n",
    ").item_collection()\n",
    "\n",
    "print(f\"{len(items_s2)} S2 scenes found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geobox\n",
    "geobox_s2 = GeoBox.from_bbox(bounds, crs=f\"epsg:{epsg}\", resolution=dx)\n",
    "\n",
    "# Load S2 data into datacube\n",
    "dc_s2 = odc.stac.load(\n",
    "    items_s2,\n",
    "    bands=[\"red\", \"nir\", \"scl\"],\n",
    "    chunks={\"x\": 512, \"y\": 512},\n",
    "    groupby=\"solar_day\",\n",
    "    geobox=geobox_s2,\n",
    "    resampling={\n",
    "        \"red\": \"bilinear\",\n",
    "        \"nir\": \"bilinear\",\n",
    "        \"scl\": \"nearest\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Aggregate time dimension\n",
    "dc_s2 = xr.Dataset({\n",
    "    \"red\": dc_s2.red.median(dim='time'),\n",
    "    \"nir\": dc_s2.nir.median(dim='time'),\n",
    "    \"scl\": dc_s2.scl.max(dim='time')\n",
    "})\n",
    "\n",
    "print(f\"S2 datacube shape: {dc_s2.red.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Build up the S2 exclusion mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute NDVI\n",
    "dc_s2[\"ndvi\"] = compute_ndvi_band(dc_s2)\n",
    "\n",
    "# Create validity mask combining SCL and NDVI threshold\n",
    "# Current: valid_S2 = (SCL valid) & (NDVI <= 0.6) for highly vegetated areas\n",
    "dc_s2[\"valid_S2\"] = (is_valid_pixel_s2(dc_s2.scl)) & (dc_s2.ndvi <= 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Register S2 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coregister S2 predictions to datacube\n",
    "dc_s2[\"S2_mu\"] = (s2mu_result_latlon\n",
    "                  .rio.reproject_match(dc_s2[\"valid_S2\"])\n",
    "                  .squeeze(drop=True)\n",
    "                  .rename({\"y\": \"latitude\", \"x\": \"longitude\"}))\n",
    "\n",
    "dc_s2[\"S2_sigma\"] = (s2sigma_result_latlon\n",
    "                     .rio.reproject_match(dc_s2[\"valid_S2\"])\n",
    "                     .squeeze(drop=True)\n",
    "                     .rename({\"y\": \"latitude\", \"x\": \"longitude\"}))\n",
    "\n",
    "print(\"S2 data successfully registered to datacube\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Merge S1 and S2 Datacubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine S1 and S2 datacubes\n",
    "combined_dc = xr.merge([dc_s2, dc])\n",
    "\n",
    "print(f\"Combined datacube variables: {list(combined_dc.data_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Fuse Masked Gaussian Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare masked inputs\n",
    "masked_μ1 = combined_dc[\"S1_mu\"].where(combined_dc[\"valid_S1\"])\n",
    "masked_σ1 = combined_dc[\"S1_sigma\"].where(combined_dc[\"valid_S1\"])\n",
    "masked_μ2 = combined_dc[\"S2_mu\"].where(combined_dc[\"valid_S2\"])\n",
    "masked_σ2 = combined_dc[\"S2_sigma\"].where(combined_dc[\"valid_S2\"])\n",
    "\n",
    "# Fuse masked Gaussian distributions\n",
    "masked_fused_mu, masked_fused_sigma = fuse_gaussians(\n",
    "    masked_μ1, masked_σ1, masked_μ2, masked_σ2\n",
    ")\n",
    "\n",
    "# Store in datacube\n",
    "combined_dc[\"masked_fused_mu\"] = masked_fused_mu\n",
    "combined_dc[\"masked_fused_sigma\"] = masked_fused_sigma\n",
    "\n",
    "print(\"Masked Gaussian fusion complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Fuse Gaussian Distributions (Unmasked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse original (unmasked) Gaussian distributions for eventual comparison\n",
    "μ1 = combined_dc[\"S1_mu\"]\n",
    "σ1 = combined_dc[\"S1_sigma\"]\n",
    "μ2 = combined_dc[\"S2_mu\"]\n",
    "σ2 = combined_dc[\"S2_sigma\"]\n",
    "\n",
    "fused_mu, fused_sigma = fuse_gaussians(μ1, σ1, μ2, σ2)\n",
    "\n",
    "# Store in datacube\n",
    "combined_dc[\"fused_mu\"] = fused_mu\n",
    "combined_dc[\"fused_sigma\"] = fused_sigma\n",
    "\n",
    "print(\"Unmasked Gaussian fusion complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final datacube structure\n",
    "print(\"\\n=== Final Combined Datacube ===\")\n",
    "print(f\"Dimensions: {combined_dc.dims}\")\n",
    "print(f\"\\nVariables:\")\n",
    "for var in combined_dc.data_vars:\n",
    "    print(f\"  - {var}: {combined_dc[var].shape}\")\n",
    "\n",
    "print(\"\\n=== Available Data Products ===\")\n",
    "print(\"S1 products: S1_mu, S1_sigma, valid_S1\")\n",
    "print(\"S2 products: S2_mu, S2_sigma, valid_S2, ndvi\")\n",
    "print(\"Fused products: masked_fused_mu, masked_fused_sigma, fused_mu, fused_sigma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optional: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Export fused masked results to GeoTIFF\n",
    "# output_path = \"/path/to/output/\"\n",
    "# combined_dc[\"masked_fused_mu\"].rio.to_raster(f\"{output_path}/fused_masked_mu.tif\")\n",
    "# combined_dc[\"masked_fused_sigma\"].rio.to_raster(f\"{output_path}/fused_masked_sigma.tif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
